{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#***Remove duplicates from ECG Files and create a filtered file:***\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dqGWPYL_n7g1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmdpDxkvn3tb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "folder = \"/sise/nadav-group/nadavrap-group/ECGs/ECG files\"\n",
        "\n",
        "# Map (ID, LEAD) → list of filenames\n",
        "id_lead_to_files = defaultdict(list)\n",
        "\n",
        "# Step 1: Build mapping from (ID, LEAD) to list of filenames\n",
        "for filename in os.listdir(folder):\n",
        "    if filename.endswith(\".xml\"):\n",
        "        parts = filename.replace(\".xml\", \"\").split(\"_\")\n",
        "        if len(parts) >= 4:\n",
        "            id_ = parts[0]\n",
        "            lead = parts[1]\n",
        "            key = (id_, lead)\n",
        "            id_lead_to_files[key].append(filename)\n",
        "\n",
        "# Step 2: Extract only those with duplicates and group them into tuples\n",
        "duplicate_tuples = []\n",
        "\n",
        "for key, files in id_lead_to_files.items():\n",
        "    if len(files) > 1:\n",
        "        duplicate_tuples.append(tuple(files))  # convert list of filenames to tuple\n",
        "\n",
        "# Output results\n",
        "print(\"Number of (ID, LEAD) groups with duplicates:\", len(duplicate_tuples))\n",
        "print(\"Example duplicate tuples:\")\n",
        "for t in duplicate_tuples[:5]:  # show first 5\n",
        "    print(t)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "source_dir = \"/sise/nadav-group/nadavrap-group/ECGs/ECG files\"\n",
        "dest_dir = \"/sise/nadav-group/nadavrap-group/ECGs/ECG files filtered\"\n",
        "\n",
        "# Create destination directory if it doesn't exist\n",
        "os.makedirs(dest_dir, exist_ok=True)\n",
        "\n",
        "# Flatten all filenames in duplicate tuples that end with 3_0.xml\n",
        "excluded_files = set()\n",
        "\n",
        "for tpl in duplicate_tuples:\n",
        "    for fname in tpl:\n",
        "        if fname.endswith(\"3_0.xml\"):\n",
        "            excluded_files.add(fname)\n",
        "\n",
        "# Copy all files except the excluded ones\n",
        "copied_count = 0\n",
        "\n",
        "for filename in os.listdir(source_dir):\n",
        "    if filename.endswith(\".xml\") and filename not in excluded_files:\n",
        "        src_path = os.path.join(source_dir, filename)\n",
        "        dst_path = os.path.join(dest_dir, filename)\n",
        "        shutil.copy2(src_path, dst_path)\n",
        "        copied_count += 1\n",
        "\n",
        "print(\"✅ Copy complete.\")\n",
        "print(f\"Total files copied: {copied_count}\")\n",
        "print(f\"Total files excluded (3_0 in duplicate tuples): {len(excluded_files)}\")"
      ],
      "metadata": {
        "id": "1GUgEAkxoXEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#***Preprocess - Daubechies wavelet 4 + Filtering Ivalid Signals:***\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "bt8aTSWeojLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install PyWavelets"
      ],
      "metadata": {
        "id": "XfVoFWbxpc47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import xml.etree.ElementTree as ET\n",
        "import pywt\n",
        "from scipy.ndimage import uniform_filter1d\n",
        "\n",
        "# Paths\n",
        "input_dir = \"/sise/nadav-group/nadavrap-group/ECGs/ECG files filtered\"\n",
        "output_dir = \"/sise/nadav-group/nadavrap-group/ECGs/Final Project/Preprocessing/Filtered_Files_updated\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Load ECG signals from XML\n",
        "def load_signals_from_xml(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    signals = {}\n",
        "    for waveform in root.findall(\".//WaveformData\"):\n",
        "        lead_name = waveform.attrib['lead']\n",
        "        signal_data = waveform.text.strip()\n",
        "        signals[lead_name] = np.array([float(x) for x in signal_data.split(',')])\n",
        "    return signals\n",
        "\n",
        "# Remove DC using moving average\n",
        "def remove_moving_average_dc(signal, window_size):\n",
        "    moving_avg = uniform_filter1d(signal, size=window_size, mode='reflect')\n",
        "    return signal - moving_avg\n",
        "\n",
        "# DWT-based denoising with DC removal\n",
        "def preprocess_ecg_dwt(signal, wavelet='db4', level=4, fs=500, window_size_sec=0.5):\n",
        "    window_size = int(window_size_sec * fs)\n",
        "    signal_no_dc = remove_moving_average_dc(signal, window_size)\n",
        "    coeffs = pywt.wavedec(signal_no_dc, wavelet, level=level)\n",
        "    threshold = np.median(np.abs(coeffs[-1])) / 0.6745 * np.sqrt(2 * np.log(len(signal)))\n",
        "    coeffs[1:] = [pywt.threshold(c, threshold, mode='soft') for c in coeffs[1:]]\n",
        "    cleaned_signal = pywt.waverec(coeffs, wavelet)\n",
        "    return cleaned_signal[:len(signal)]\n",
        "\n",
        "# Main loop over all XML files\n",
        "fs = 500\n",
        "window_size_sec = 0.5\n",
        "# Define directory for invalid signals\n",
        "invalid_dir = \"/sise/nadav-group/nadavrap-group/ECGs/Final Project/Preprocessing/Invalid_Signals\"\n",
        "os.makedirs(invalid_dir, exist_ok=True)\n",
        "count = 0\n",
        "for filename in os.listdir(input_dir):\n",
        "    if filename.endswith(\".xml\"):\n",
        "        file_path = os.path.join(input_dir, filename)\n",
        "        print(f\"Processing: {file_path}\")\n",
        "\n",
        "        raw_signals = load_signals_from_xml(file_path)\n",
        "        base_name = os.path.splitext(filename)[0]\n",
        "\n",
        "        for lead, signal in raw_signals.items():\n",
        "            denoised_signal = preprocess_ecg_dwt(signal, fs=fs, window_size_sec=window_size_sec)\n",
        "            # Remove NaNs or Infs\n",
        "\n",
        "            # After preprocessing each signal:\n",
        "            if np.isnan(denoised_signal).any() or np.isinf(denoised_signal).any():\n",
        "                print(f\"❌ Invalid values found in {filename}, lead: {lead}\")\n",
        "\n",
        "                # Save invalid signal for debugging\n",
        "                invalid_filename = f\"{base_name}_lead_{lead}_INVALID.npy\"\n",
        "                invalid_path = os.path.join(invalid_dir, invalid_filename)\n",
        "                np.save(invalid_path, denoised_signal)\n",
        "                count += 1\n",
        "                continue  # Skip saving this signal to the main output\n",
        "            # Save as .npy\n",
        "            output_file = os.path.join(output_dir, f\"{base_name}_lead_{lead}_denoised.npy\")\n",
        "            np.save(output_file, denoised_signal)\n",
        "print(\"count of invalid signals:\", count)\n",
        "\n",
        "print(\"All files processed and saved.\")"
      ],
      "metadata": {
        "id": "v-dbK20kpXkn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}